---
title: Ask Agent
description: Get quick responses from agents without interrupting execution
---

<Note>
This example is available on GitHub: [examples/01_standalone_sdk/28_ask_agent_example.py](https://github.com/All-Hands-AI/agent-sdk/blob/main/examples/01_standalone_sdk/28_ask_agent_example.py)
</Note>

Learn how to use `ask_agent()` to get quick responses from the agent about the current conversation state without interrupting the main execution flow.

```python icon="python" expandable examples/01_standalone_sdk/28_ask_agent_example.py
```

```bash Running the Example
export LLM_API_KEY="your-api-key"
# Optional overrides
# export LLM_MODEL="anthropic/claude-sonnet-4-5-20250929"
# export LLM_BASE_URL="https://your-llm-base-url"

cd agent-sdk
uv run python examples/01_standalone_sdk/28_ask_agent_example.py
```

### How It Works

- Create a conversation and start a long-running task:

```python
conversation = Conversation(agent=agent, workspace=".")
conversation.send_message("Your main task message")
```

- While the conversation is running, use `ask_agent()` to get quick responses:

```python
response = conversation.ask_agent("What is the current status?")
print(f"Agent response: {response}")
```

- The `ask_agent()` method:
  - Does not interrupt the main conversation flow
  - Returns a quick response based on the current conversation state
  - Can be called multiple times during execution
  - Useful for monitoring progress or getting status updates

### Use Cases

- **Progress monitoring**: Check how far along a task is
- **Status queries**: Ask about current state or next steps
- **Debug information**: Get insights into what the agent is doing
- **Interactive monitoring**: Build UIs that show real-time updates

## Next Steps

- **[Conversation Management](/sdk/guides/conversation)** – Learn more about conversation APIs
- **[Async Operations](/sdk/guides/async)** – Handle asynchronous agent interactions
