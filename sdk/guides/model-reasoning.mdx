---
title: Model Reasoning
description: Access model reasoning traces from Anthropic thinking blocks and OpenAI responses API.
---

<Note>
This example is available on GitHub: [examples/01_standalone_sdk/22_model_reasoning.py](https://github.com/All-Hands-AI/agent-sdk/blob/main/examples/01_standalone_sdk/22_model_reasoning.py)
</Note>

View your agent's internal reasoning process for debugging, transparency, and understanding decision-making. This example demonstrates two approaches:

1. **Anthropic Extended Thinking** - Claude's thinking blocks for complex reasoning
2. **OpenAI Responses Reasoning** - GPT's reasoning effort parameter

```python icon="python" expandable examples/01_standalone_sdk/22_model_reasoning.py
"""
Example: Model Reasoning - Anthropic Thinking & OpenAI Responses

Demonstrates two approaches to accessing model reasoning:
1. Anthropic's extended thinking feature with thinking blocks
2. OpenAI's Responses API with reasoning effort parameter

Both approaches allow you to see the model's internal reasoning process
for transparency, debugging, and understanding decision-making.
"""

from __future__ import annotations

import os

from pydantic import SecretStr

from openhands.sdk import (
    LLM,
    Agent,
    Conversation,
    Event,
    LLMConvertibleEvent,
    RedactedThinkingBlock,
    ThinkingBlock,
    get_logger,
)
from openhands.sdk.tool import Tool, register_tool
from openhands.tools.execute_bash import BashTool
from openhands.tools.preset.default import get_default_agent


logger = get_logger(__name__)


def example_anthropic_thinking():
    """Demonstrate Anthropic Claude's extended thinking with thinking blocks."""
    print("\n" + "=" * 80)
    print("EXAMPLE 1: Anthropic Extended Thinking")
    print("=" * 80)

    api_key = os.getenv("LLM_API_KEY")
    assert api_key is not None, "LLM_API_KEY environment variable is not set."
    model = os.getenv("LLM_MODEL", "openhands/claude-sonnet-4-5-20250929")
    base_url = os.getenv("LLM_BASE_URL")

    llm = LLM(
        usage_id="agent",
        model=model,
        base_url=base_url,
        api_key=SecretStr(api_key),
    )

    # Setup agent with bash tool
    register_tool("BashTool", BashTool)
    agent = Agent(llm=llm, tools=[Tool(name="BashTool")])

    # Callback to display thinking blocks
    def show_thinking(event: Event):
        if isinstance(event, LLMConvertibleEvent):
            message = event.to_llm_message()
            if hasattr(message, "thinking_blocks") and message.thinking_blocks:
                print(f"\nüß† Found {len(message.thinking_blocks)} thinking blocks")
                for i, block in enumerate(message.thinking_blocks):
                    if isinstance(block, RedactedThinkingBlock):
                        print(f"  Block {i + 1}: {block.data}")
                    elif isinstance(block, ThinkingBlock):
                        preview = block.thinking[:100]
                        print(f"  Block {i + 1}: {preview}...")

    conversation = Conversation(
        agent=agent, callbacks=[show_thinking], workspace=os.getcwd()
    )

    conversation.send_message(
        "Calculate compound interest for $10,000 at 5% annually, "
        "compounded quarterly for 3 years. Show your work.",
    )
    conversation.run()

    conversation.send_message(
        "Now, write that number to ANTHROPIC_RESULT.txt.",
    )
    conversation.run()
    print("‚úÖ Anthropic thinking example complete!")


def example_openai_responses():
    """Demonstrate OpenAI's Responses API with reasoning effort."""
    print("\n" + "=" * 80)
    print("EXAMPLE 2: OpenAI Responses Reasoning")
    print("=" * 80)

    api_key = os.getenv("LLM_API_KEY") or os.getenv("OPENAI_API_KEY")
    assert api_key, "Set LLM_API_KEY or OPENAI_API_KEY in your environment."

    model = os.getenv("LLM_MODEL", "openhands/gpt-5-codex")
    base_url = os.getenv("LLM_BASE_URL")

    llm = LLM(
        model=model,
        api_key=SecretStr(api_key),
        base_url=base_url,
        # Responses-path options
        reasoning_effort="high",
        # Logging / behavior tweaks
        log_completions=False,
        usage_id="agent",
    )

    agent = get_default_agent(
        llm=llm,
        cli_mode=True,  # disable browser tools for env simplicity
    )

    llm_messages = []  # collect raw LLM-convertible messages for inspection

    def conversation_callback(event: Event):
        if isinstance(event, LLMConvertibleEvent):
            msg = event.to_llm_message()
            llm_messages.append(msg)
            # Show reasoning if available
            if hasattr(msg, "reasoning") and msg.reasoning:
                preview = str(msg.reasoning)[:100]
                print(f"üí≠ Reasoning detected: {preview}...")

    conversation = Conversation(
        agent=agent,
        callbacks=[conversation_callback],
        workspace=os.getcwd(),
    )

    # Keep the tasks short for demo purposes
    conversation.send_message("Create a file called OPENAI_RESULT.txt with a fun fact.")
    conversation.run()

    conversation.send_message("Now delete OPENAI_RESULT.txt.")
    conversation.run()

    print("=" * 80)
    print(f"‚úÖ Collected {len(llm_messages)} LLM messages with reasoning traces")
    print("‚úÖ OpenAI responses example complete!")


if __name__ == "__main__":
    # Detect which model is being used and run appropriate example
    model = os.getenv("LLM_MODEL", "")

    if "claude" in model.lower() or "anthropic" in model.lower():
        print("üîç Detected Anthropic model - running thinking blocks example")
        example_anthropic_thinking()
    elif "gpt" in model.lower() or "openai" in model.lower():
        print("üîç Detected OpenAI model - running responses reasoning example")
        example_openai_responses()
    else:
        print("‚ö†Ô∏è  Model not specified or unclear. Running both examples...")
        print("   Set LLM_MODEL to 'claude-...' or 'gpt-...' to run specific example")
        try:
            example_anthropic_thinking()
        except Exception as e:
            print(f"‚ö†Ô∏è  Anthropic example failed: {e}")

        try:
            example_openai_responses()
        except Exception as e:
            print(f"‚ö†Ô∏è  OpenAI example failed: {e}")

    print("\n" + "=" * 80)
    print("‚úÖ All reasoning examples complete!")
    print("=" * 80)
```

```bash Running the Example
# For Anthropic Claude
export LLM_API_KEY="your-anthropic-api-key"
export LLM_MODEL="openhands/claude-sonnet-4-5-20250929"
cd agent-sdk
uv run python examples/01_standalone_sdk/22_model_reasoning.py

# For OpenAI GPT
export LLM_API_KEY="your-openai-api-key"
export LLM_MODEL="openhands/gpt-5-codex"
cd agent-sdk
uv run python examples/01_standalone_sdk/22_model_reasoning.py
```

## Anthropic Thinking Blocks

Access Claude's internal thinking process with thinking blocks:

```python highlight={7-12}
def show_thinking(event: Event):
    if isinstance(event, LLMConvertibleEvent):
        message = event.to_llm_message()
        if hasattr(message, "thinking_blocks") and message.thinking_blocks:
            print(f"üß† Found {len(message.thinking_blocks)} thinking blocks")
            for block in message.thinking_blocks:
                if isinstance(block, RedactedThinkingBlock):
                    print(f"Redacted: {block.data}")
                elif isinstance(block, ThinkingBlock):
                    print(f"Thinking: {block.thinking}")

conversation = Conversation(agent=agent, callbacks=[show_thinking])
```

Claude uses thinking blocks to reason through complex problems step-by-step, improving accuracy on difficult tasks.

## OpenAI Responses Reasoning

Access GPT's reasoning traces with the responses API:

```python highlight={6}
llm = LLM(
    model="gpt-5-codex",
    api_key=SecretStr(api_key),
    base_url=base_url,
    # Enable reasoning with effort level
    reasoning_effort="high",
)
```

Then capture reasoning in your callback:

```python highlight={4-6}
def conversation_callback(event: Event):
    if isinstance(event, LLMConvertibleEvent):
        msg = event.to_llm_message()
        if hasattr(msg, "reasoning") and msg.reasoning:
            print(f"üí≠ Reasoning: {msg.reasoning}")
```

## Use Cases

**Debugging**: Understand why the agent made specific decisions or took certain actions.

**Transparency**: Show users how the AI arrived at its conclusions.

**Quality Assurance**: Identify flawed reasoning patterns or logic errors.

**Learning**: Study how models approach complex problems.

## Next Steps

- **[Interactive Terminal](/sdk/guides/interactive-terminal)** - Display reasoning in real-time
- **[LLM Metrics](/sdk/guides/llm-metrics)** - Track token usage and performance
- **[Custom Tools](/sdk/guides/custom-tools)** - Add specialized capabilities
