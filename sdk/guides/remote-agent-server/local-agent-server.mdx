---
title: Local Agent Server & Workspaces
description: Understand workspaces and run agent server locally for client-server architecture.
---

<Note>
This example is available on GitHub: [examples/02_remote_agent_server/01_convo_with_local_agent_server.py](https://github.com/All-Hands-AI/agent-sdk/blob/main/examples/02_remote_agent_server/01_convo_with_local_agent_server.py)
</Note>

Workspaces define where agents execute commands and access files. This guide introduces workspace concepts and demonstrates the local agent server setup.

## Workspace Types

| Type | Security | Setup | Use Case |
|------|----------|-------|----------|
| **LocalWorkspace** | Low (host access) | None | Development |
| **DockerWorkspace** | High (isolated) | Docker | Testing, Production |
| **RemoteAPIWorkspace** | High (isolated) | Server | Multi-user, Cloud |

## LocalWorkspace

Execute directly on your machine - default for standalone SDK.

### Usage

```python
from openhands.sdk import Conversation

# LocalWorkspace is implicit (no workspace parameter needed)
conversation = Conversation(agent=agent)
conversation.send_message("Create a Python script")
conversation.run()
```

Operations run in current working directory with direct host access.

### When to Use

- **Development** - Quick iteration and testing
- **Local files** - Direct access to local filesystem
- **Simple tasks** - No isolation needed

### Security Considerations

⚠️ **Warning**: Agent has full host access:
- Can modify any accessible files
- Can execute any commands
- **Not recommended for production or untrusted code**

## Remote Agent Server

Run agent server and connect remotely for resource isolation and scalability.

### How to Run

```bash
# Terminal 1: Start server
export LLM_API_KEY="your-api-key"
cd agent-sdk
uv run python -m openhands.agent_server

# Terminal 2: Run client
export LLM_API_KEY="your-api-key"
uv run python examples/02_remote_agent_server/01_convo_with_local_agent_server.py
```

### Client Connection

```python
from openhands.sdk import RemoteConversation

conversation = RemoteConversation(
    agent_server_url="http://localhost:8000",
    api_key=api_key
)
conversation.send_message("Your task")
conversation.run()
```

### Benefits

- **Resource Isolation** - Server handles compute-intensive tasks
- **Scalability** - Multiple clients connect to same server
- **Deployment** - Separate client and execution environments
- **Security** - Isolate agent execution from client

## Related Documentation

- **[Docker Sandboxed Server](/sdk/guides/remote-agent-server/02-docker-sandboxed-server)** - Isolated execution
- **[Agent Server Architecture](/sdk/architecture/agent-server)** - Server details
- **[Workspace Architecture](/sdk/architecture/sdk/workspace)** - Technical design
