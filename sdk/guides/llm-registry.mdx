---
title: LLM Registry
description: Dynamically select and configure language models using the LLM registry.
---

<Note>
This example is available on GitHub: [examples/01_standalone_sdk/05_use_llm_registry.py](https://github.com/All-Hands-AI/agent-sdk/blob/main/examples/01_standalone_sdk/05_use_llm_registry.py)
</Note>

Use the LLM registry to manage multiple LLM providers and dynamically switch between models:

```python icon="python" expandable examples/01_standalone_sdk/05_use_llm_registry.py
import os

from pydantic import SecretStr

from openhands.sdk import (
    LLM,
    Agent,
    Conversation,
    Event,
    LLMConvertibleEvent,
    LLMRegistry,
    Message,
    TextContent,
    get_logger,
)
from openhands.sdk.tool import Tool, register_tool
from openhands.tools.execute_bash import BashTool


logger = get_logger(__name__)

# Configure LLM using LLMRegistry
api_key = os.getenv("LLM_API_KEY")
assert api_key is not None, "LLM_API_KEY environment variable is not set."
model = os.getenv("LLM_MODEL", "openhands/claude-sonnet-4-5-20250929")
base_url = os.getenv("LLM_BASE_URL")

# Create LLM instance
main_llm = LLM(
    usage_id="agent",
    model=model,
    base_url=base_url,
    api_key=SecretStr(api_key),
)

# Create LLM registry and add the LLM
llm_registry = LLMRegistry()
llm_registry.add(main_llm)

# Get LLM from registry
llm = llm_registry.get("agent")

# Tools
cwd = os.getcwd()
register_tool("BashTool", BashTool)
tools = [Tool(name="BashTool")]

# Agent
agent = Agent(llm=llm, tools=tools)

llm_messages = []  # collect raw LLM messages


def conversation_callback(event: Event):
    if isinstance(event, LLMConvertibleEvent):
        llm_messages.append(event.to_llm_message())


conversation = Conversation(
    agent=agent, callbacks=[conversation_callback], workspace=cwd
)

conversation.send_message("Please echo 'Hello!'")
conversation.run()

print("=" * 100)
print("Conversation finished. Got the following LLM messages:")
for i, message in enumerate(llm_messages):
    print(f"Message {i}: {str(message)[:200]}")

print("=" * 100)
print(f"LLM Registry usage IDs: {llm_registry.list_usage_ids()}")

# Demonstrate getting the same LLM instance from registry
same_llm = llm_registry.get("agent")
print(f"Same LLM instance: {llm is same_llm}")

# Demonstrate requesting a completion directly from an LLM
completion_response = llm.completion(
    messages=[
        Message(role="user", content=[TextContent(text="Say hello in one word.")])
    ]
)
# Access the response content
if completion_response.choices and completion_response.choices[0].message:  # type: ignore
    content = completion_response.choices[0].message.content  # type: ignore
    print(f"Direct completion response: {content}")
else:
    print("No response content available")
```

```bash Running the Example
export LLM_API_KEY="your-api-key"
export LLM_MODEL="openhands/claude-sonnet-4-5-20250929"
cd agent-sdk
uv run python examples/01_standalone_sdk/05_use_llm_registry.py
```

### Using the Registry

Get pre-configured LLMs from the registry by model name:

```python highlight={3-6}
from openhands.sdk import get_llm_from_registry

llm = get_llm_from_registry(
    model="openhands/claude-sonnet-4-5-20250929",
    api_key=SecretStr(api_key)
)
```

### Multi-Model Applications

Use different models for different task complexities:

```python highlight={1-2,5,8}
cheap_llm = get_llm_from_registry("openhands/gpt-4o-mini", api_key=api_key)
powerful_llm = get_llm_from_registry("openhands/claude-sonnet-4-5-20250929", api_key=api_key)

# Use cheap model for simple tasks
simple_agent = Agent(llm=cheap_llm, tools=tools)

# Use powerful model for complex tasks
complex_agent = Agent(llm=powerful_llm, tools=tools)
```

## Next Steps

- **[LLM Routing](/sdk/guides/llm-routing)** - Automatically route to different models
- **[LLM Metrics](/sdk/guides/llm-metrics)** - Track token usage and costs
