---
title: openhands.sdk.agent
description: API reference for openhands.sdk.agent module
---


### class Agent

Bases: [AgentBase](#class-agentbase)

Main agent implementation for OpenHands.

The Agent class provides the core functionality for running AI agents that can
interact with tools, process messages, and execute actions. It inherits from
AgentBase and implements the agent execution logic.

Example


#### Methods

#### init_state()

Initialize conversation state.
Invariants enforced by this method:
- If a SystemPromptEvent is already present, it must be within the first 3
- A user MessageEvent should not appear before the SystemPromptEvent.
These invariants keep event ordering predictable for downstream components
(condenser, UI, etc.) and also prevent accidentally materializing the full
event history during initialization.

#### model_config = (configuration object)

Configuration for the model, should be a dictionary conforming to [`ConfigDict`][pydantic.config.ConfigDict].

#### model_post_init()

This function is meant to behave like a BaseModel method to initialise private attributes.
It takes context as an argument since that’s what pydantic-core passes when calling it.
* Parameters:
  * `self` – The BaseModel instance.
  * `context` – The context.

#### step()

Taking a step in the conversation.
Typically this involves:
1. Making a LLM call
2. Executing the tool
3. Updating the conversation state with
4.1 If conversation is finished, set state.execution_status to FINISHED
4.2 Otherwise, just return, Conversation will kick off the next step
If the underlying LLM supports streaming, partial deltas are forwarded to
`on_token` before the full response is returned.
NOTE: state will be mutated in-place.


### class AgentBase

Bases: `DiscriminatedUnionMixin`, `ABC`

Abstract base class for OpenHands agents.

Agents are stateless and should be fully defined by their configuration.
This base class provides the common interface and functionality that all
agent implementations must follow.


#### Properties

- `agent_context`: AgentContext | None ¶
- `condenser`: CondenserBase | None ¶
- `critic`: CriticBase | None ¶
- `filter_tools_regex`: str | None ¶
- `include_default_tools`: list[str] ¶
- `llm`: LLM ¶
- `mcp_config`: dict[str, Any] ¶
- `name`: str ¶
  Returns the name of the Agent.
- `prompt_dir`: str ¶
  Returns the directory where this class’s module file is located.
- `security_policy_filename`: str ¶
- `system_message`: str ¶
  Compute system message on-demand to maintain statelessness.
- `system_prompt_filename`: str ¶
- `system_prompt_kwargs`: dict[str, object] ¶
- `tools`: list[Tool] ¶
- `tools_map`: dict[str, ToolDefinition] ¶
  Get the initialized tools map.
:raises RuntimeError: If the agent has not been initialized.

#### Methods

#### get_all_llms()

Recursively yield unique base-class LLM objects reachable from `self`.
- Returns actual object references (not copies).
- De-dupes by `id(LLM)`.
- Cycle-safe via a visited set for all traversed objects.
- Only yields objects whose type is exactly `LLM` (no subclasses).
- Does not handle dataclasses.

#### init_state()

Initialize the empty conversation state to prepare the agent for user
messages.
Typically this involves adding system message
NOTE: state will be mutated in-place.

#### model_config = (configuration object)

Configuration for the model, should be a dictionary conforming to [`ConfigDict`][pydantic.config.ConfigDict].

#### model_dump_succint()

Like model_dump, but excludes None fields by default.

#### model_post_init()

This function is meant to behave like a BaseModel method to initialise private attributes.
It takes context as an argument since that’s what pydantic-core passes when calling it.
* Parameters:
  * `self` – The BaseModel instance.
  * `context` – The context.

#### step()

Taking a step in the conversation.
Typically this involves:
1. Making a LLM call
2. Executing the tool
3. Updating the conversation state with
4.1 If conversation is finished, set state.execution_status to FINISHED
4.2 Otherwise, just return, Conversation will kick off the next step
If the underlying LLM supports streaming, partial deltas are forwarded to
`on_token` before the full response is returned.
NOTE: state will be mutated in-place.

#### verify()

Verify that we can resume this agent from persisted state.
We do not merge configuration between persisted and runtime Agent
instances. Instead, we verify compatibility requirements and then
continue with the runtime-provided Agent.
Compatibility requirements:
- Agent class/type must match.
- Tools must match exactly (same tool names).
Tools are part of the system prompt and cannot be changed mid-conversation.
To use different tools, start a new conversation or use conversation forking
(see [https://github.com/OpenHands/OpenHands/issues/8560](https://github.com/OpenHands/OpenHands/issues/8560)).
All other configuration (LLM, agent_context, condenser, etc.) can be
freely changed between sessions.
* Parameters:
  * `persisted` – The agent loaded from persisted state.
  * `events` – Unused, kept for API compatibility.
* Returns:
  This runtime agent (self) if verification passes.
* Raises:
  ValueError – If agent class or tools don’t match.

