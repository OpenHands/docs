---
title: openhands.sdk.agent
description: API reference for openhands.sdk.agent
---

## class Agent

Bases: `AgentBase`

Main agent implementation for OpenHands.

The Agent class provides the core functionality for running AI agents that can
interact with tools, process messages, and execute actions. It inherits from
AgentBase and implements the agent execution logic.

### Methods

**init_state(state: ConversationState, on_event: ConversationCallbackType) -> None**

Initialize conversation state.

Invariants enforced by this method:
- If a SystemPromptEvent is already present, it must be within the first 3
  events (index 0 or 1 in practice; index 2 is included in the scan window
  to detect a user message appearing before the system prompt).
- A user MessageEvent should not appear before the SystemPromptEvent.

These invariants keep event ordering predictable for downstream components
(condenser, UI, etc.) and also prevent accidentally materializing the full
event history during initialization.

**step(conversation: LocalConversation, on_event: ConversationCallbackType, on_token: ConversationTokenCallbackType | None = None) -> None**

## class AgentBase

Bases: `DiscriminatedUnionMixin`, `ABC`

Abstract base class for OpenHands agents.

Agents are stateless and should be fully defined by their configuration.
This base class provides the common interface and functionality that all
agent implementations must follow.

### Properties

- `model_config`
- `llm`: LLM
  LLM configuration for the agent.
- `tools`: list[Tool]
  List of tools to initialize for the agent.
- `mcp_config`: dict[str, Any]
  Optional MCP configuration dictionary to create MCP tools.
- `filter_tools_regex`: str | None
  Optional regex to filter the tools available to the agent by name. This is applied after any tools provided in `tools` and any MCP tools are added.
- `include_default_tools`: list[str]
  List of default tool class names to include. By default, the agent includes 
- `agent_context`: AgentContext | None
  Optional AgentContext to initialize the agent with specific context.
- `system_prompt_filename`: str
  System prompt template filename. Can be either:\n- A relative filename (e.g., 
- `security_policy_filename`: str
  Security policy template filename. Can be either:\n- A relative filename (e.g., 
- `system_prompt_kwargs`: dict[str, object]
  Optional kwargs to pass to the system prompt Jinja2 template.
- `condenser`: CondenserBase | None
  Optional condenser to use for condensing conversation history.
- `critic`: CriticBase | None
  EXPERIMENTAL: Optional critic to evaluate agent actions and messages in real-time. API and behavior may change without notice. May impact performance, especially in 
- `prompt_dir`: str
  Returns the directory where this class's module file is located.
- `name`: str
  Returns the name of the Agent.
- `system_message`: str
  Compute system message on-demand to maintain statelessness.
- `tools_map`: dict[str, ToolDefinition]
  Get the initialized tools map.
Raises:
    RuntimeError: If the agent has not been initialized.

### Methods

**init_state(state: ConversationState, on_event: ConversationCallbackType) -> None**

Initialize the empty conversation state to prepare the agent for user
messages.

Typically this involves adding system message

NOTE: state will be mutated in-place.

**abstractmethod step(conversation: LocalConversation, on_event: ConversationCallbackType, on_token: ConversationTokenCallbackType | None = None) -> None**

Taking a step in the conversation.

Typically this involves:
1. Making a LLM call
2. Executing the tool
3. Updating the conversation state with
    LLM calls (role="assistant") and tool results (role="tool")
4.1 If conversation is finished, set state.execution_status to FINISHED
4.2 Otherwise, just return, Conversation will kick off the next step

If the underlying LLM supports streaming, partial deltas are forwarded to
``on_token`` before the full response is returned.

NOTE: state will be mutated in-place.

**verify(persisted: AgentBase, events: Sequence[Any] | None = None) -> AgentBase**

Verify that we can resume this agent from persisted state.

We do not merge configuration between persisted and runtime Agent
instances. Instead, we verify compatibility requirements and then
continue with the runtime-provided Agent.

Compatibility requirements:
- Agent class/type must match.
- Tools must match exactly (same tool names).

Tools are part of the system prompt and cannot be changed mid-conversation.
To use different tools, start a new conversation or use conversation forking
(see https://github.com/OpenHands/OpenHands/issues/8560).

All other configuration (LLM, agent_context, condenser, etc.) can be
freely changed between sessions.

**Parameters:**

- `persisted` *AgentBase* – The agent loaded from persisted state.
- `events` *Sequence[Any] | None* – Unused, kept for API compatibility.

**Returns:**

- *AgentBase* This runtime agent (self) if verification passes.

**Raises:**

- `ValueError` – If agent class or tools don't match.

**model_dump_succint(kwargs = \{\})**

Like model_dump, but excludes None fields by default.

**get_all_llms() -> Generator[LLM, None, None]**

Recursively yield unique *base-class* LLM objects reachable from `self`.

- Returns actual object references (not copies).
- De-dupes by `id(LLM)`.
- Cycle-safe via a visited set for *all* traversed objects.
- Only yields objects whose type is exactly `LLM` (no subclasses).
- Does not handle dataclasses.
