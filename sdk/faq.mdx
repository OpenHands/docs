---
title: FAQ
description: Frequently asked questions about the OpenHands SDK
icon: question
---

## How do I use AWS Bedrock with the SDK?

**Yes, the OpenHands SDK supports AWS Bedrock through LiteLLM.**

Since LiteLLM requires `boto3` for Bedrock requests, you need to install it alongside the SDK.

<Accordion title="Setup Instructions" icon="gear">

### Step 1: Install boto3

Install the SDK with boto3:

```bash
# Using pip
pip install openhands-sdk boto3

# Using uv
uv pip install openhands-sdk boto3

# Or when installing as a CLI tool
uv tool install openhands --with boto3
```

### Step 2: Configure Authentication

You have two authentication options:

**Option A: API Key Authentication (Recommended)**

Use the `AWS_BEARER_TOKEN_BEDROCK` environment variable:

```bash
export AWS_BEARER_TOKEN_BEDROCK="your-bedrock-api-key"
```

**Option B: AWS Credentials**

Use traditional AWS credentials:

```bash
export AWS_ACCESS_KEY_ID="your-access-key"
export AWS_SECRET_ACCESS_KEY="your-secret-key"
export AWS_REGION_NAME="us-west-2"
```

### Step 3: Configure the Model

Use the `bedrock/` prefix for your model name:

```python
from openhands.sdk import LLM, Agent

llm = LLM(
    model="bedrock/anthropic.claude-3-sonnet-20240229-v1:0",
    # api_key is read from AWS_BEARER_TOKEN_BEDROCK automatically
)
```

For cross-region inference profiles, include the region prefix:

```python
llm = LLM(
    model="bedrock/us.anthropic.claude-3-5-sonnet-20240620-v1:0",  # US region
    # or
    model="bedrock/apac.anthropic.claude-sonnet-4-20250514-v1:0",  # APAC region
)
```

### CLI Configuration

When using the OpenHands CLI, configure Bedrock in the LLM (Advanced) settings:

- **Model**: `bedrock/anthropic.claude-3-sonnet-20240229-v1:0`
- **Custom URL**: `https://bedrock-runtime.<region>.amazonaws.com`
- **API Key**: Your Bedrock API key

</Accordion>

For more details on Bedrock configuration options, see the [LiteLLM Bedrock documentation](https://docs.litellm.ai/docs/providers/bedrock).

## Does the agent SDK support parallel tool calling?

**Yes, the OpenHands SDK supports parallel tool calling by default.**

The SDK automatically handles parallel tool calls when the underlying LLM (like Claude or GPT-4) returns multiple tool calls in a single response. This allows agents to execute multiple independent actions before the next LLM call.

<Accordion title="How it works" icon="gear">
When the LLM generates multiple tool calls in parallel, the SDK groups them using a shared `llm_response_id`:

```python
ActionEvent(llm_response_id="abc123", thought="Let me check...", tool_call=tool1)
ActionEvent(llm_response_id="abc123", thought=[], tool_call=tool2)
# Combined into: Message(role="assistant", content="Let me check...", tool_calls=[tool1, tool2])
```

Multiple `ActionEvent`s with the same `llm_response_id` are grouped together and combined into a single LLM message with multiple `tool_calls`. Only the first event's thought/reasoning is included. The parallel tool calling implementation can be found in the [Events Architecture](/sdk/arch/events#event-types) for detailed explanation of how parallel function calling works, the [`prepare_llm_messages` in utils.py](https://github.com/OpenHands/software-agent-sdk/blob/main/openhands-sdk/openhands/sdk/agent/utils.py) which groups ActionEvents by `llm_response_id` when converting events to LLM messages, the [agent step method](https://github.com/OpenHands/software-agent-sdk/blob/main/openhands-sdk/openhands/sdk/agent/agent.py#L200-L300) where actions are created with shared `llm_response_id`, and the [`ActionEvent` class](https://github.com/OpenHands/software-agent-sdk/blob/main/openhands-sdk/openhands/sdk/event/llm_convertible/action.py) which includes the `llm_response_id` field. For more details, see the **[Events Architecture](/sdk/arch/events)** for a deep dive into the event system and parallel function calling, the **[Tool System](/sdk/arch/tool-system)** for understanding how tools work with the agent, and the **[Agent Architecture](/sdk/arch/agent)** for how agents process and execute actions.
</Accordion>

## More questions?

If you have additional questions:

- **[Join our Slack Community](https://openhands.dev/joinslack)** - Ask questions and get help from the community
- **[GitHub Discussions](https://github.com/OpenHands/software-agent-sdk/discussions)** - Start a discussion
- **[GitHub Issues](https://github.com/OpenHands/software-agent-sdk/issues)** - Report bugs or request features
