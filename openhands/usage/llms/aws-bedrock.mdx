---
title: AWS Bedrock
description: OpenHands can work with AWS Bedrock models using an OpenAI-compatible API endpoint.
---

## Configuration

AWS Bedrock provides OpenAI-compatible API endpoints for their models. You can find their documentation on using the OpenAI Chat Completions API [here](https://docs.aws.amazon.com/bedrock/latest/userguide/inference-chat-completions.html).

To configure OpenHands to use AWS Bedrock:

1. In the OpenHands UI, navigate to Settings under the `LLM` tab
2. Enable `Advanced` options
3. Set the following:
   - `Custom Model` to `openai/{model_name}` (e.g. `openai/anthropic.claude-3-5-sonnet-20240620-v1:0`)
   - `Base URL` to `https://bedrock-runtime.{region}.amazonaws.com/openai/v1` (e.g. `https://bedrock-runtime.us-west-2.amazonaws.com/openai/v1`)
   - `API Key` to your AWS Bedrock API key

<Note>
The `openai/` prefix in the Custom Model field indicates that OpenHands should use an OpenAI-compatible API format. It does not mean you are directly calling the OpenAI provider.
</Note>

<Note>
Replace `{region}` with your desired AWS region (e.g., `us-west-2`, `us-east-1`). Ensure the region you specify matches where your Bedrock models are available.
</Note>
